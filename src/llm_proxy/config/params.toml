[llm_proxy_node.ros__parameters]
default_model = "gpt35"
request_timeout = 30.0

[llm_proxy_node.ros__parameters.models.gpt35]
name = "gpt-3.5-turbo"
api_endpoint = "https://api.openai.com/v1/chat/completions"
api_key = "OPENAI_API_KEY"  # Will be filled in during runtime there is it's env name
default_temperature = 0.7
default_max_tokens = 1024
model_format = "openai"

[llm_proxy_node.ros__parameters.models.gpt4]
name = "gpt-4"
api_endpoint = "https://api.openai.com/v1/chat/completions"
api_key = "ANTHROPIC_API_KEY"
default_temperature = 0.7
default_max_tokens = 2048
model_format = "openai"

[llm_proxy_node.ros__parameters.models.claude]
name = "claude-3-opus-20240229"
api_endpoint = "https://api.anthropic.com/v1/messages"
api_key = ""
default_temperature = 0.7
default_max_tokens = 4096
model_format = "anthropic"

[llm_proxy_node.ros__parameters.models.zhipu]
name = "glm-4"
api_endpoint = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
api_key = "ZHIPU_API_KEY"
default_temperature = 0.7
default_max_tokens = 2048
model_format = "openai"  # ZhiPu API is OpenAI compatible

[llm_proxy_node.ros__parameters.models.qwen]
name = "qwen"
api_endpoint = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
api_key = "ZHIPU_API_KEY"
default_temperature = 0.7
default_max_tokens = 2048
model_format = "openai"  # ZhiPu API is OpenAI compatible
